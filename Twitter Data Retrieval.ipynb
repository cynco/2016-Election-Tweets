{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Retrieval and Pre-processing\n",
    "\n",
    "The general procedure will be:     \n",
    "-[Retrieve the data from Twitter API](#Retrieving-data-from-Twitter-API)    \n",
    "-[Look for previously data,load it to a temp data frame](#Look-for-previously-data,-load-it-to-a-temp-data-frame)    \n",
    "-[Create a tweet search function](#Create-a-tweet-search-function)    \n",
    "-[Perform some checks on the combined data](#Perform-some-checks-on-the-combined-data)    \n",
    "-[Write the data to CSV and Rda files](#Write-the-data-to-CSV-and-Rda-files)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving data from Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clear all variables and devices\n",
    "rm(list=ls())\n",
    "invisible(dev.off())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptions of packages to be used\n",
    "\n",
    "  twitteR: Twitter Web API the provides an interface to Twitter Data  \n",
    "  twitteR: Twitter Web API the provides an interface to Twitter Data  \n",
    "  ROAuth:  Allows users to connect users to the server and authenticate via OAuth package  \n",
    "  RCurl:   General network (HTTP/FTP/..) client interface for R  \n",
    "  httr:    Tools for working with URLs and HTTP  \n",
    "  lubridate: Make dealing with dates easier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "The following object is masked from ‘package:twitteR’:\n",
      "\n",
      "    id\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "The following objects are masked from ‘package:twitteR’:\n",
      "\n",
      "    id, location\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "The following object is masked from ‘package:plyr’:\n",
      "\n",
      "    here\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    date\n",
      "\n",
      "Installing package into ‘/Users/cynthiacorrea/Library/R/3.3/library’\n",
      "(as ‘lib’ is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/yb/zv0jpymj5yn6bqf2s2x4yjx80000gn/T//Rtmp25wNNN/downloaded_packages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "20"
      ],
      "text/latex": [
       "20"
      ],
      "text/markdown": [
       "20"
      ],
      "text/plain": [
       "[1] 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Load the required packages (if packages are not available, \n",
    "#  then install them first)\n",
    "for (package in c('twitteR', 'ROAuth', 'RCurl', \n",
    "                  'httr', 'plyr', 'dplyr', 'stringr', 'lubridate')) {\n",
    "  if (!require(package, character.only=T, quietly=T)) {\n",
    "    invisible(install.packages(package))\n",
    "    library(package, character.only=T)\n",
    "  }\n",
    "}\n",
    "\n",
    "invisible(install.packages(\"base64enc\", dependencies=T))\n",
    "library(base64enc)\n",
    "\n",
    "# Confirm that all packages got loaded\n",
    "length(search()) # 20 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  Declare Local Variables for previously downloaded Twitter data\n",
    "file.path <- \"/Users/cynthiacorrea/TwitterProject/Jupyter/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access data, Twitter requires one to create an application. Private keys are generated which give secure access to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  OAuth settings for twitter:\n",
    "#  library(httr)\n",
    "oauth_endpoints(\"twitter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Using direct authentication\"\n"
     ]
    }
   ],
   "source": [
    "#  Access keys from Twitter application (API) at https://apps.twitter.com/\n",
    "#  THESE KEYS SHOULD BE KEPT PRIVATE\n",
    "\n",
    "api_key <- \"kACQPjXUxG7NPH7sD0h1CHo6K\"\n",
    "api_secret <- \"AVrQEityBmlI1ScDuPm63O0eo5NyYgrz09DzNTBfkCPMhMZOmy\"\n",
    "access_token <- \"782078006869233664-7LPW0rJ7e7wzn9nVD9TwlxLZrknK4ot\"\n",
    "access_token_secret <- \"J5kkVNqExzcdahnkEOvEPmSqTVrePl0NMWjPLC0EU471e\"\n",
    "\n",
    "setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After connecting to the API, you submit a request for data based on a search string and other parameters, such as the maximum number of tweets, the dates, lattitudes, and language.\n",
    "\n",
    "\n",
    "Sample Twitter Search Command\n",
    "\n",
    "      searchTwitter('Donald Trump', n=10000, \n",
    "                    since=Sys.Date(), until=Sys.Date(), \n",
    "                    geocode='39.8,-95.583068847656,2500km',\n",
    "                    retryOnRateLimit=25, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"end.date\" \"17113\"   \n"
     ]
    }
   ],
   "source": [
    "tweet.db.start.date <- \"2016-11-07\"  # First day of tweets database creation, October 1st.\n",
    "\n",
    "orig.run.flag <- FALSE  # flag to indicate initial search for new tweets\n",
    "re.run.flag <- TRUE     # flag to indicate re-run for tweets search\n",
    "\n",
    "run.date <- Sys.Date()-1   # default run date set to yesterday\n",
    "re.check.date <- run.date  # holds first date within the dataset\n",
    "end.date <- Sys.Date()     # default end date set to today\n",
    "\n",
    "print(c('end.date', end.date))    ###!\n",
    "\n",
    "no.of.tweets <- 10000   # number of tweets set to 10,000\n",
    "search.str <- c('Donald Trump', 'Hillary Clinton')\n",
    "\n",
    "temp.combined.tweets <- NULL\n",
    "\n",
    "# The following warning messages may be displayed after twitter search is\n",
    "# executed any time. These can be ignored.\n",
    "#\n",
    "# Warning messages:\n",
    "#   1: In doRppAPICall(\"search/tweets\", n, params = params, retryOnRateLimit = retryOnRateLimit,  :\n",
    "#                        10000 tweets were requested but the API can only return 0\n",
    "#   2: In doRppAPICall(\"search/tweets\", n, params = params, retryOnRateLimit = retryOnRateLimit,  :\n",
    "#                                           10000 tweets were requested but the API can only return 0\n",
    "#   3: In rbind_all(x) : Unequal factor levels: coercing to character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for previously data, load it to a temp data frame \n",
    "\n",
    "If there exists previously downloaded data in a file named \"DownloadedTweets.Rda\", it is loaded into a temp data frame named **\"temp.combined.tweets\"**. I retrieve the beginning and end dates, update the date variables to download a new batch of data. I create a data frame with useful parameters such as number of days, all the search parameters, and the highest tweet ID number for each candidate. This is all stored in the **\"search.parms.df\"**. \n",
    "\n",
    "Else, if there is no previously downloaded data, the search parameters data frame is created and filled with the current days parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"No previously saved data file found\"\n"
     ]
    }
   ],
   "source": [
    "# Search for the tweets data in the local directory referenced\n",
    "# by the variable file.path set earlier.\n",
    "#\n",
    "if (file.exists(paste0(file.path, \"DownloadedTweets.Rda\"))) {\n",
    "  \n",
    "  print(\"Found previously saved data file\")\n",
    "  \n",
    "  load(file=paste0(file.path, \"DownloadedTweets.Rda\"))\n",
    "  print(\"Marker -5\")\n",
    "  \n",
    "  # Save the loaded data frame to a temporary data frame\n",
    "  temp.combined.tweets <- combined.tweets\n",
    "    \n",
    "  print('Dimensions of temp.combined.tweets')    ###!\n",
    "  dim(temp.combined.tweets)\n",
    "  \n",
    "  # Since data exists for previous day(s), re-check will be required\n",
    "  re.run.flag <- TRUE\n",
    "  print(\"Marker -4\")\n",
    "  \n",
    "  # Get the last date in the downloaded dataset\n",
    "  created.max <- as.Date(max(combined.tweets$created))\n",
    "  \n",
    "  # Get the first date in the downloaded dataset\n",
    "  re.check.date <- as.Date(min(combined.tweets$created))\n",
    "  print(c(\"Marker -3, created.max\", created.max))\n",
    "  \n",
    "  # run date is set to day after the last date in the dataset\n",
    "  run.date <- created.max + 1\n",
    "  \n",
    "  # If run date is found to be greater than end date, then\n",
    "  # tweets for all dates have already been searched previously.\n",
    "  # Set the simple search for tweets flag to FALSE; else,\n",
    "  # set the simple search for tweets flag to TRUE\n",
    "  if (run.date >= end.date) {\n",
    "    orig.run.flag <- FALSE\n",
    "  } else {\n",
    "    orig.run.flag <- TRUE\n",
    "  }\n",
    "  print(\"Marker -2, end.date, re.check.date\")\n",
    "  print(end.date)\n",
    "    rint(re.check.date)\n",
    "  # Create the parameters table\n",
    "  \n",
    "  # m is the difference between the current/end date and the first\n",
    "  # date within the dataset\n",
    "  m <- as.numeric(end.date - re.check.date)\n",
    "  print(c(\"Marker -1, m=\",m))\n",
    "  \n",
    "  # Set a sequence from one to the difference of above dates.\n",
    "  # This is done to set the dates in the reverse chronological order.\n",
    "  from.date <- m:1\n",
    "  print('marker0')\n",
    "  \n",
    "  # Set the first three parameters of the parameter table\n",
    "  date.from <- Sys.Date() - from.date\n",
    "  from.days <- m:1   # Round 2: 10/17/2016\n",
    "  date.since <- format(Sys.Date()-from.days)\n",
    "  \n",
    "  # Create a data frame containing all search parameters \n",
    "  # from all combinations of - date.since, no.of.tweets, and search.str\n",
    "  search.parms.df <- data.frame(expand.grid(date.since = date.since, \n",
    "                                            no.of.tweets = no.of.tweets, \n",
    "                                            search.str = search.str))\n",
    "  \n",
    "  # Extract and set the day value of date since column\n",
    "  search.parms.df$day.of.month <- mday(search.parms.df$date.since)\n",
    "  print('marker1')\n",
    "  \n",
    "  # add 'date.until' after creating the above frame - \n",
    "  # just a day's difference is required from 'date.since' for each row\n",
    "  search.parms.df$date.until <- format(Sys.Date()-(from.days-1))\n",
    "  \n",
    "  # For each candidate, get the maximum tweet ID for each day  \n",
    "  data.aggr <- aggregate(id ~ search.str+mday(created), \n",
    "                         data=combined.tweets, max)\n",
    "  names(data.aggr) <- c(\"search.str\", \"day.of.month\", \"since.id\")\n",
    "  print('marker2')\n",
    "  \n",
    "  # Merge the above data frame with the parameters table frame\n",
    "  search.parms.df <- merge(x=search.parms.df, y=data.aggr,\n",
    "                           by=c(\"search.str\", \"day.of.month\"), all.x=T) \n",
    "  \n",
    "} else {  # if the tweets data file does not exist\n",
    "  \n",
    "  print(\"No previously saved data file found\")\n",
    "  \n",
    "  re.run.flag <- FALSE  # when no previous data exists, re-run not reqd\n",
    "  \n",
    "  # Run date is set to October 1st to search for all tweets since Oct 1\n",
    "  # run.date <- as.Date(\"2016-10-01\")\n",
    "  run.date <- as.Date(tweet.db.start.date)\n",
    "  \n",
    "  orig.run.flag = TRUE   # tweets for new date needs to be searched\n",
    "  \n",
    "  # m is the difference between the current/end date and the first\n",
    "  # date within the dataset\n",
    "  m <- as.numeric(end.date - run.date)\n",
    "  \n",
    "  from.date <- m:1\n",
    "  \n",
    "  # Set the first three parameters of the parameter table\n",
    "  date.from <- Sys.Date() - from.date\n",
    "  from.days <- m:1   # Round 2: 10/17/2016\n",
    "  date.since <- format(Sys.Date()-from.days)\n",
    "  \n",
    "  # Create a data frame containing all search parameters \n",
    "  # from all combinations of - date.since, no.of.tweets, and search.str\n",
    "  search.parms.df <- data.frame(expand.grid(date.since = date.since, \n",
    "                                            no.of.tweets = no.of.tweets, \n",
    "                                            search.str = search.str))\n",
    "  \n",
    "  # Extract and set the day value of date since column\n",
    "  search.parms.df$day.of.month <- mday(search.parms.df$date.since)\n",
    "  \n",
    "  # add 'date.until' after creating the above frame - \n",
    "  # just a day's difference is required from 'date.since' for each row\n",
    "  search.parms.df$date.until <- format(Sys.Date()-(from.days-1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dimensions of search.parms.df\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Dimensions of search.parms.df')    ###!\n",
    "dim(search.parms.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I perform some checks on the parameters data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2 obs. of  5 variables:\n",
      " $ date.since  : Factor w/ 1 level \"2016-11-07\": 1 1\n",
      " $ no.of.tweets: num  10000 10000\n",
      " $ search.str  : Factor w/ 2 levels \"Donald Trump\",..: 1 2\n",
      " $ day.of.month: int  7 7\n",
      " $ date.until  : chr  \"2016-11-08\" \"2016-11-08\"\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of parameters data frame\n",
    "str(search.parms.df)\n",
    "# 'data.frame':\t72 obs. of  5 variables:\n",
    "#  $ date.since  : Factor w/ 36 levels \"2016-10-01\",\"2016-10-02\",..: 1 2 3 4 5 6 7 8 9 10 ...\n",
    "#  $ no.of.tweets: num  10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 ...\n",
    "#  $ search.str  : Factor w/ 2 levels \"Donald Trump\",..: 1 1 1 1 1 1 1 1 1 1 ...\n",
    "#  $ day.of.month: int  1 2 3 4 5 6 7 8 9 10 ...\n",
    "#  $ date.until  : chr  \"2016-10-02\" \"2016-10-03\" \"2016-10-04\" \"2016-10-05\" ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>date.since</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>no.of.tweets</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>search.str</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>day.of.month</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>date.until</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[date.since] TRUE\n",
       "\\item[no.of.tweets] FALSE\n",
       "\\item[search.str] TRUE\n",
       "\\item[day.of.month] FALSE\n",
       "\\item[date.until] FALSE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "date.since\n",
       ":   TRUEno.of.tweets\n",
       ":   FALSEsearch.str\n",
       ":   TRUEday.of.month\n",
       ":   FALSEdate.until\n",
       ":   FALSE\n",
       "\n"
      ],
      "text/plain": [
       "  date.since no.of.tweets   search.str day.of.month   date.until \n",
       "        TRUE        FALSE         TRUE        FALSE        FALSE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Modify all factor columns to character columns.\n",
    "# This is required since the searchString input for searchTwitter function\n",
    "# should be in character format.\n",
    "# First, check which columns of parameters data frame are factor columns\n",
    "# sapply is from family of apply functions available in the base package.\n",
    "# It facilitates executing a function on each element of a \n",
    "# vector (list, matrix, or dataframe)\n",
    "rowIndex <- sapply(search.parms.df, is.factor)\n",
    "\n",
    "rowIndex\n",
    "# date.since\n",
    "# TRUE\n",
    "# no.of.tweets\n",
    "# FALSE\n",
    "# search.str\n",
    "# TRUE\n",
    "# day.of.month\n",
    "# FALSE\n",
    "# date.until\n",
    "# FALSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"search.parms.df\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>date.since</th><th scope=col>search.str</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2016-11-07     </td><td>Donald Trump   </td></tr>\n",
       "\t<tr><td>2016-11-07     </td><td>Hillary Clinton</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " date.since & search.str\\\\\n",
       "\\hline\n",
       "\t 2016-11-07      & Donald Trump   \\\\\n",
       "\t 2016-11-07      & Hillary Clinton\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  date.since search.str     \n",
       "1 2016-11-07 Donald Trump   \n",
       "2 2016-11-07 Hillary Clinton"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('search.parms.df')\n",
    "head(search.parms.df[rowIndex])\n",
    "#    date.since      search.str\n",
    "# 1  2016-10-01    Donald Trump\n",
    "# 2  2016-10-02    Donald Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then modify the factor columns to character columns\n",
    "# lapply returns a list of the same length as X\n",
    "# All columns applied for modifications using lapply are modified\n",
    "search.parms.df[rowIndex] <- lapply(search.parms.df[rowIndex], \n",
    "                                    as.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"dim of search.parms.df\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>2</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 2\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 2\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 2 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('dim of search.parms.df')\n",
    "dim(search.parms.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2 obs. of  5 variables:\n",
      " $ date.since  : chr  \"2016-11-07\" \"2016-11-07\"\n",
      " $ no.of.tweets: num  10000 10000\n",
      " $ search.str  : chr  \"Donald Trump\" \"Hillary Clinton\"\n",
      " $ day.of.month: int  7 7\n",
      " $ date.until  : chr  \"2016-11-08\" \"2016-11-08\"\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Check the structure of parms\n",
    "str(search.parms.df)\n",
    "\n",
    "# 'data.frame':\t72 obs. of  6 variables:\n",
    "#  $ search.str  : chr  \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" ...\n",
    "#  $ day.of.month: int  1 1 10 11 12 13 14 15 16 17 ...\n",
    "#  $ date.since  : chr  \"2016-10-01\" \"2016-11-01\" \"2016-10-10\" \"2016-10-11\" ...\n",
    "#  $ no.of.tweets: num  10000 10000 10000 10000 10000 10000 10000 10000 10000 10000 ...\n",
    "\n",
    "#  rbind warning can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>date.since</th><th scope=col>no.of.tweets</th><th scope=col>search.str</th><th scope=col>day.of.month</th><th scope=col>date.until</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2016-11-07     </td><td>10000          </td><td>Donald Trump   </td><td>7              </td><td>2016-11-08     </td></tr>\n",
       "\t<tr><td>2016-11-07     </td><td>10000          </td><td>Hillary Clinton</td><td>7              </td><td>2016-11-08     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " date.since & no.of.tweets & search.str & day.of.month & date.until\\\\\n",
       "\\hline\n",
       "\t 2016-11-07      & 10000           & Donald Trump    & 7               & 2016-11-08     \\\\\n",
       "\t 2016-11-07      & 10000           & Hillary Clinton & 7               & 2016-11-08     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  date.since no.of.tweets search.str      day.of.month date.until\n",
       "1 2016-11-07 10000        Donald Trump    7            2016-11-08\n",
       "2 2016-11-07 10000        Hillary Clinton 7            2016-11-08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display records in the parameters data frame\n",
    "head(search.parms.df, 5)  # default is 6 rows\n",
    "\n",
    "# search.str\tday.of.month\tdate.since\tno.of.tweets\tdate.until\tsince.id\n",
    "# Donald Trump\t1\t2016-10-01\t10000\t2016-10-02\t793603522440802304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tweet search function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to search tweets based on parameters such as the string to be searched, number of tweets, date from, date until, and since ID. If date from, date until, and since ID parameter values are not passed to this function, then the default NULL (current date for date fields and no value for since ID) is assumed. \n",
    "\n",
    "The resultType parameter is not used since the default 'mixed' option enables searching for tweets that are both popular and recent for the given time period. The parameters geocode, lang, and retryOnRateLimit are hard coded and set to locations within USA; in English language; and, block search command retry up to 25 times if rate limit is experienced, respectively.\n",
    "\n",
    "Here, only original tweets are kept in **\"ret.tweets.df\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  tweets.df = function(search.str, no.of.tweets, \n",
    "                     date.since = NULL, date.until = NULL,\n",
    "                     since.id = NULL) {\n",
    "  \n",
    "  print (paste0(\"Searching \", no.of.tweets, \" tweets for ...\" ,\n",
    "                search.str, \" from \", date.since, \" to \", \n",
    "                date.until, \" since \", since.id, \".\"))\n",
    "  \n",
    "  ret.tweets <- searchTwitter(searchString = search.str, n = no.of.tweets, \n",
    "                              since = date.since, until = date.until,\n",
    "                              sinceID = since.id,\n",
    "                              geocode = '39.8,-95.583068847656,2500km', \n",
    "                              lang = \"en\", retryOnRateLimit = 25)\n",
    "  \n",
    "  # If no tweets are found, return an empty data frame\n",
    "  if (length(ret.tweets) <= 0) {\n",
    "    return (data.frame())\n",
    "  }\n",
    "  \n",
    "  # Remove newer style retweets and both older style retweets (RT) and \n",
    "  # modified tweets (MT). Retain 'original' tweets only\n",
    "  ret.tweets <- tryCatch(\n",
    "    {\n",
    "      strip_retweets(ret.tweets, strip_manual = TRUE, \n",
    "                     strip_mt = TRUE)\n",
    "    },\n",
    "    warning = function(w) {\n",
    "      print(\"Warning: All Tweets returned are Retweets\")\n",
    "      return (NULL)\n",
    "    },\n",
    "    error = function(e) {\n",
    "      print(\"Beware: All Tweets returned are Retweets\")\n",
    "      return (NULL)\n",
    "    }\n",
    "  )\n",
    "  \n",
    "  print (paste0(\"Retrieved \", length(ret.tweets), \" tweets for ...\" ,\n",
    "                search.str, \" from \", date.since, \" to \", \n",
    "                date.until, \" since \", since.id, \".\"))\n",
    "  print(c('since.id', since.id))\n",
    "  print('date.until')\n",
    "  print(date.until)\n",
    "      \n",
    "  # Re-check if the set of returned tweets list is null or empty\n",
    "  if (is.null(ret.tweets) | length(ret.tweets) <= 0) {\n",
    "    return (data.frame())\n",
    "  }\n",
    "    # Convert the returned tweets list to a data frame\n",
    "  ret.tweets.df <- twListToDF(ret.tweets)\n",
    "  print('Dimensions of ret.tweets.df')    ###!\n",
    "  dim(ret.tweets.df)\n",
    "  \n",
    "  # Ensure numeric values are saved in the lat and lon fields\n",
    "  ret.tweets.df$longitude <- as.numeric(ret.tweets.df$longitude)\n",
    "  ret.tweets.df$latitude <- as.numeric(ret.tweets.df$latitude)\n",
    "  \n",
    "  # The function cbind of the base package binds column(s) to a list,\n",
    "  # vector or a matrix\n",
    "  return(cbind(search.str, ret.tweets.df))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following condition occurs when tweets for new date/day is to be searched, but there is NO existing data for other dates. Each row of the parameter table is looped through to build parameters for and executing the tweets search function. The new tweets are stored in **\"combined.tweets\"**.\n",
    "\n",
    "The combined data frame for all days is checked for duplicate rows. It is saved in csv and Rda formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Searching 10000 tweets for ...Donald Trump from 2016-11-07 to 2016-11-08 since .\"\n",
      "[1] \"Retrieved 2433 tweets for ...Donald Trump from 2016-11-07 to 2016-11-08 since .\"\n",
      "[1] \"since.id\"\n",
      "[1] \"date.until\"\n",
      "[1] \"2016-11-08\"\n",
      "[1] \"Dimensions of ret.tweets.df\"\n",
      "[1] \"Searching 10000 tweets for ...Hillary Clinton from 2016-11-07 to 2016-11-08 since .\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 24 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 23 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 22 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 21 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 20 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 19 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 18 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 17 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 16 times ...\"\n",
      "[1] \"Rate limited .... blocking for a minute and retrying up to 15 times ...\"\n",
      "[1] \"Retrieved 2153 tweets for ...Hillary Clinton from 2016-11-07 to 2016-11-08 since .\"\n",
      "[1] \"since.id\"\n",
      "[1] \"date.until\"\n",
      "[1] \"2016-11-08\"\n",
      "[1] \"Dimensions of ret.tweets.df\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in rbind_all(x, .id):\n",
      "“Unequal factor levels: coercing to character”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Searching 10000 tweets for ...Donald Trump from 2016-11-07 to 2016-11-08 since 795777853245648901.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in doRppAPICall(\"search/tweets\", n, params = params, retryOnRateLimit = retryOnRateLimit, :\n",
      "“10000 tweets were requested but the API can only return 2”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Beware: All Tweets returned are Retweets\"\n",
      "[1] \"Retrieved 0 tweets for ...Donald Trump from 2016-11-07 to 2016-11-08 since 795777853245648901.\"\n",
      "[1] \"since.id\"           \"795777853245648901\"\n",
      "[1] \"date.until\"\n",
      "[1] \"2016-11-08\"\n",
      "[1] \"Searching 10000 tweets for ...Hillary Clinton from 2016-11-07 to 2016-11-08 since 795777851626655744.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in doRppAPICall(\"search/tweets\", n, params = params, retryOnRateLimit = retryOnRateLimit, :\n",
      "“10000 tweets were requested but the API can only return 5”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Beware: All Tweets returned are Retweets\"\n",
      "[1] \"Retrieved 0 tweets for ...Hillary Clinton from 2016-11-07 to 2016-11-08 since 795777851626655744.\"\n",
      "[1] \"since.id\"           \"795777851626655744\"\n",
      "[1] \"date.until\"\n",
      "[1] \"2016-11-08\"\n"
     ]
    }
   ],
   "source": [
    "if (orig.run.flag == TRUE & re.run.flag == FALSE) {\n",
    "  \n",
    "  combined.tweets <- \n",
    "    bind_rows(lapply(1:nrow(search.parms.df), \n",
    "                     function(x) tweets.df(search.parms.df$search.str[x], \n",
    "                                           no.of.tweets=no.of.tweets, \n",
    "                                           date.since=search.parms.df$date.since[x], \n",
    "                                           date.until=search.parms.df$date.until[x]))) %>% \n",
    "    as.data.frame()\n",
    "}\n",
    "\n",
    "\n",
    "# Although the above two \"if\" commands can be combined into one by removing the\n",
    "# check for re.rerun.flag, they are kept separate for the sake of clarity.\n",
    "\n",
    "\n",
    "# Combine the temporary data frame (downloaded tweets, if applicable) along with\n",
    "# the combined tweets data frame due to above searches.\n",
    "combined.tweets <- rbind(temp.combined.tweets, combined.tweets)\n",
    "\n",
    "\n",
    "# Get the maximum ID for each Candidate and Day if orig.run.flag is set.\n",
    "# If searches for new tweets were launched, then the data aggregation step will\n",
    "# have to be repeated to find the maximum tweets ID for each candidate and\n",
    "# new day(s).\n",
    "#\n",
    "if (orig.run.flag == TRUE) {\n",
    "  search.parms.df$since.id <- NULL\n",
    "  data.aggr <- aggregate(id ~ search.str+mday(created), \n",
    "                         data=combined.tweets, max)\n",
    "  names(data.aggr) <- c(\"search.str\", \"day.of.month\", \"since.id\")\n",
    "  search.parms.df <- merge(x=search.parms.df, y=data.aggr,\n",
    "                           by=c(\"search.str\", \"day.of.month\"), all.x=T) \n",
    "}\n",
    "\n",
    "\n",
    "# Once again, save the existing tweets data frame to a temporary data frame\n",
    "temp.combined.tweets <- combined.tweets\n",
    "\n",
    "\n",
    "# Search again for more tweets by providing the since ID for each parameter\n",
    "# combination. These parameter combinations (without since ID) were used for\n",
    "# tweets search earlier.\n",
    "#\n",
    "combined.tweets <- \n",
    "  bind_rows(lapply(1:nrow(search.parms.df), \n",
    "                   function(x) tweets.df(search.parms.df$search.str[x], \n",
    "                                         no.of.tweets=no.of.tweets, \n",
    "                                         date.since=search.parms.df$date.since[x], \n",
    "                                         date.until=search.parms.df$date.until[x],\n",
    "                                         since.id=search.parms.df$since.id[x]))) %>% \n",
    "  as.data.frame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dimensions of combined tweets\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Dimensions of combined tweets')    ###!\n",
    "dim(combined.tweets)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Number of duplicate rows:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "586"
      ],
      "text/latex": [
       "586"
      ],
      "text/markdown": [
       "586"
      ],
      "text/plain": [
       "[1] 586"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dimensions of combined tweets\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>4000</li>\n",
       "\t<li>17</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4000\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4000\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4000   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the temporary data frame with the new tweets data frame\n",
    "combined.tweets <- rbind(temp.combined.tweets, combined.tweets)\n",
    "\n",
    "\n",
    "# Identify any duplicate tweets within the dataset\n",
    "idx <- sapply(combined.tweets, function(x) !is.na(match(x, x[duplicated(x)])))\n",
    "idx.val <- apply(idx,1,function(x) ifelse(all(x)==TRUE,TRUE,FALSE))\n",
    "\n",
    "\n",
    "# Find number of duplicate rows\n",
    "    \n",
    "print('Number of duplicate rows:')\n",
    "nrow(combined.tweets[which(idx.val == TRUE),])\n",
    "# [1] 3658\n",
    "\n",
    "\n",
    "# Remove duplicate rows by copying non-duplicate data set\n",
    "combined.tweets <- combined.tweets[which(idx.val == FALSE),]\n",
    "    \n",
    "print('Dimensions of combined tweets')    ###!\n",
    "dim(combined.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the downloaded tweets in Rda and CSV formatted files\n",
    "save(combined.tweets, file=paste0(file.path, \"DownloadedTweets.Rda\"))\n",
    "write.csv(combined.tweets, file=paste0(file.path, \"DownloadedTweets.csv\"),\n",
    "          row.names = F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function call with all combinations of the search parmeters except since ID.\n",
    "  \n",
    "Each row of parameter data frame that DO NOT have since ID parameter value\n",
    "populated is looped through to build parameters for and execute the search\n",
    "tweets function with the help of lapply function.\n",
    "The results returned are then stacked in one large data frame. The %>% (pipe) operator is then used to save all stacked rows in a dataframe\n",
    "\n",
    "The following condition occurrs when tweets for new date/day is to be searched, and there is existing data for other dates. Tweets for these old dates have to be checked again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (orig.run.flag == TRUE & re.run.flag == TRUE) {\n",
    "  \n",
    "  combined.tweets <- \n",
    "    bind_rows(lapply(which(is.na(search.parms.df$since.id)), \n",
    "                     function(x) tweets.df(search.parms.df$search.str[x], \n",
    "                                           no.of.tweets = no.of.tweets, \n",
    "                                           date.since = search.parms.df$date.since[x], \n",
    "                                           date.until = search.parms.df$date.until[x]))) %>% \n",
    "    as.data.frame()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform some checks on the combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"dimensions of combined.tweets\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>4000</li>\n",
       "\t<li>17</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4000\n",
       "\\item 17\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4000\n",
       "2. 17\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 4000   17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t4000 obs. of  17 variables:\n",
      " $ search.str   : chr  \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" ...\n",
      " $ text         : chr  \"Dave Chappelle -- Hell No, I Don't Support Trump! Consider the Source (VIDEO) https://t.co/WQcYdZB2zy via @TMZ\" \"in spanish today we were talking about our turn offs about ppl &amp; this quiet girl in the back of the class said \\\"don… https\"| __truncated__ \"Not saying I'm a Clinton supporter but Donald Trump once used fake medical records to get out of military service so... @g_payn\"| __truncated__ \"I keep getting recommendations to follow Donald Trump accounts, what is life anymore.\" ...\n",
      " $ favorited    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ favoriteCount: num  0 2 0 0 0 0 0 0 0 4 ...\n",
      " $ replyToSN    : chr  NA NA NA NA ...\n",
      " $ created      : POSIXct, format: \"2016-11-07 23:59:59\" \"2016-11-07 23:59:59\" ...\n",
      " $ truncated    : logi  FALSE TRUE FALSE FALSE FALSE FALSE ...\n",
      " $ replyToSID   : chr  NA NA NA NA ...\n",
      " $ id           : chr  \"795777853245648901\" \"795777853098954756\" \"795777852801159168\" \"795777851589005312\" ...\n",
      " $ replyToUID   : chr  NA NA NA NA ...\n",
      " $ statusSource : chr  \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\" ...\n",
      " $ screenName   : chr  \"JamesPerrin5\" \"abigailrichardz\" \"GavynM_\" \"Eyvo_am\" ...\n",
      " $ retweetCount : num  0 2 0 0 0 0 0 0 0 3 ...\n",
      " $ isRetweet    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ retweeted    : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ longitude    : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ latitude     : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "[1] \"dates that were not loaded\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1] \"2016-11-07 23:59:59 UTC\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the dimensions of the combined tweets data frame\n",
    "print(\"dimensions of combined.tweets\")\n",
    "dim(combined.tweets)\n",
    "# [1] 35683    17\n",
    "\n",
    "\n",
    "# Check the structure of the combined tweets data frame\n",
    "str(combined.tweets)\n",
    "# 'data.frame':\t35683 obs. of  17 variables:\n",
    "# $ search.str   : chr  \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" \"Donald Trump\" ...\n",
    "\n",
    "\n",
    "# Check which dates were not loaded\n",
    "print('dates that were not loaded')\n",
    "combined.tweets[!duplicated(day(combined.tweets$created)), c(6)]\n",
    "# [1] \"2016-10-02 23:59:59 UTC\" \"2016-10-03 23:59:58 UTC\" \"2016-10-04 23:59:59 UTC\"\n",
    "# [4] \"2016-10-05 23:59:58 UTC\" \"2016-10-06 23:59:59 UTC\" \"2016-10-07 23:59:58 UTC\"\n",
    "# [7] \"2016-10-08 23:59:59 UTC\" \"2016-10-09 23:59:59 UTC\" \"2016-10-10 23:59:59 UTC\"\n",
    "# [10] \"2016-10-11 23:59:59 UTC\"\n",
    "\n",
    "\n",
    "# For ease of date/time queries and manipulation later, add new date\n",
    "# and time fields to the tweets data frame\n",
    "#\n",
    "# library(lubridate)\n",
    "#\n",
    "combined.tweets$timestamp <- ymd_hms(combined.tweets$created)\n",
    "combined.tweets$dateonly <- trunc(combined.tweets$timestamp, \"days\")\n",
    "combined.tweets$timeonly <- round(as.numeric(combined.tweets$timestamp - \n",
    "                                               trunc(combined.tweets$timestamp, \"days\")),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the data to CSV and Rda files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the modified dataset in separate data and csv file\n",
    "save(combined.tweets, \n",
    "     file=paste0(file.path, \"ModifiedTweets1.Rda\"))\n",
    "write.csv(combined.tweets, \n",
    "          file=paste0(file.path, \"ModifiedTweets1.csv\"),\n",
    "          row.names = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
